{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Download do Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle datasets download -d jessicali9530/lfw-dataset -p ../data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -q ../data/lfw-dataset.zip -d ../data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm ../data/lfw-dataset.zip\n",
    "!rm ../data/*.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Detecção das faces**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device name: NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "from facenet_pytorch import MTCNN, extract_face, InceptionResnetV1\n",
    "import torch\n",
    "from torchvision.transforms import Compose, Resize, ToTensor, Normalize, Lambda\n",
    "from PIL import Image\n",
    "import os\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device name: {torch.cuda.get_device_name(0)}')\n",
    "\n",
    "transform = Compose(\n",
    "    [\n",
    "    Resize((160, 160)), \n",
    "    ToTensor(), \n",
    "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]\n",
    ")\n",
    "\n",
    "RAW_LFW_PATH = '../data/lfw-deepfunneled/lfw-deepfunneled/'\n",
    "FACES_PATH = '../data/lfw-faces/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcnn = MTCNN(keep_all=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_faces(raw_images_path: str, faces_images_path: str) -> pd.DataFrame:\n",
    "    if not os.path.exists(faces_images_path):\n",
    "        os.makedirs(faces_images_path)\n",
    "        \n",
    "    subfolders = os.listdir(raw_images_path)\n",
    "    \n",
    "    nobox = []\n",
    "    df = []\n",
    "    \n",
    "    for id, folder in enumerate(tqdm(subfolders, desc='Extraindo rostos', unit='img')):\n",
    "        imgs = os.listdir(f'{raw_images_path}/{folder}')\n",
    "        \n",
    "        for file in imgs:\n",
    "            save_path = os.path.join(faces_images_path, file.split('/')[-1])\n",
    "            save_path_df = os.path.join('./data/lfw-faces/', file.split('/')[-1])\n",
    "            df.append((id, save_path_df))\n",
    "            \n",
    "            img = Image.open(os.path.join(raw_images_path + folder, file))\n",
    "        \n",
    "            boxes, _ = mtcnn.detect(img)\n",
    "            \n",
    "            if boxes is not None:\n",
    "                extract_face(img, boxes[0], save_path=save_path)\n",
    "            else:\n",
    "                nobox.append(save_path_df)\n",
    "                \n",
    "    df = pd.DataFrame(df, columns=['id', 'path'])\n",
    "    \n",
    "    return nobox, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5899218a1d884714928240450826e99c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraindo rostos:   0%|          | 0/5749 [00:00<?, ?img/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de imagens sem face detectada: 1\n",
      "Número de imagens com face detectada: 13233\n",
      "Número de identidades: 5749\n"
     ]
    }
   ],
   "source": [
    "nobox, df = extract_faces(RAW_LFW_PATH, FACES_PATH)\n",
    "\n",
    "print(f'Número de imagens sem face detectada: {len(nobox)}')\n",
    "print(f'Número de imagens com face detectada: {len(df)}')\n",
    "print(f'Número de identidades: {df[\"id\"].nunique()}')\n",
    "\n",
    "# Removendo imagens sem face detectada do df\n",
    "df = df[~df['path'].isin(nobox)]\n",
    "\n",
    "# Salvando o csv\n",
    "df.to_csv('../data/lfw_faces.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>./data/lfw-faces/Koichiro_Matsuura_0001.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>./data/lfw-faces/Mark_Hanson_0001.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>./data/lfw-faces/Gregorio_Honasan_0001.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>./data/lfw-faces/Shanna_Zolman_0001.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>./data/lfw-faces/Edward_Seaga_0001.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                         path\n",
       "0   0  ./data/lfw-faces/Koichiro_Matsuura_0001.jpg\n",
       "1   1        ./data/lfw-faces/Mark_Hanson_0001.jpg\n",
       "2   2   ./data/lfw-faces/Gregorio_Honasan_0001.jpg\n",
       "3   3      ./data/lfw-faces/Shanna_Zolman_0001.jpg\n",
       "4   4       ./data/lfw-faces/Edward_Seaga_0001.jpg"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Split de treino e teste**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ../data/lfw-deepfunneled/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identidades no conjunto de teste: 49\n",
      "Imagens no conjunto de teste: 567\n",
      "\n",
      "Identidades no conjunto de treino: 5700\n",
      "Imagens no conjunto de treino: 12665\n"
     ]
    }
   ],
   "source": [
    "ids_count = df['id'].value_counts()\n",
    "valid_ids = ids_count[ids_count >= 5].index\n",
    "\n",
    "shuffled_ids = valid_ids.to_numpy()\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(shuffled_ids)\n",
    "\n",
    "test_ids = shuffled_ids[:49]\n",
    "\n",
    "# Criar os dataframes de treino e teste\n",
    "test_df = df[df['id'].isin(test_ids)]\n",
    "train_df = df[~df['id'].isin(test_ids)]\n",
    "\n",
    "print(f\"Identidades no conjunto de teste: {test_df['id'].nunique()}\")\n",
    "print(f\"Imagens no conjunto de teste: {len(test_df)}\\n\")\n",
    "\n",
    "print(f\"Identidades no conjunto de treino: {train_df['id'].nunique()}\")\n",
    "print(f\"Imagens no conjunto de treino: {len(train_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Extração dos embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = InceptionResnetV1(pretrained='vggface2').eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_embeddings(model, train_df, transform, device) -> list:\n",
    "    embeddings = []\n",
    "    for i, row in tqdm(train_df.iterrows(), total=len(train_df)):\n",
    "        img = Image.open(row['path'])\n",
    "        img = transform(img).to(device)\n",
    "        img_embedding = model(img.unsqueeze(0)).detach().cpu().numpy()\n",
    "        embeddings.append(img_embedding)\n",
    "    \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = extract_embeddings(resnet, train_df, transform, device)\n",
    "train_df['embedding'] = embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_pickle('../data/lfw_train_embeddings.pkl')\n",
    "test_df.to_csv('../data/lfw_test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
